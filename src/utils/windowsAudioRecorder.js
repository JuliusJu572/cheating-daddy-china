const { ipcRenderer, desktopCapturer } = require('electron');
const fs = require('fs');
const path = require('path');
const os = require('os');
const { pcmToWav } = require('../audioUtils');

let isRecording = false;
let audioContext = null;
let mediaStream = null;
let processor = null;
let sourceNode = null;
let recordedChunks = [];
const TARGET_SAMPLE_RATE = 16000; // Gemini supports 16kHz or 24kHz, 16kHz is safer for consistent processing

async function toggleRecording() {
    console.log('[WindowsAudioRecorder] Toggle recording triggered. Current state:', isRecording);
    if (isRecording) {
        await stopRecording();
    } else {
        await startRecording();
    }
}

async function startRecording() {
    try {
        // ç«‹å³ç»™ç”¨æˆ·åé¦ˆ
        ipcRenderer.send('update-status', 'Initializing Microphone...');
        console.log('[WindowsAudioRecorder] Starting Microphone Capture...');
        recordedChunks = [];

        // ä½¿ç”¨ getUserMedia èŽ·å–éº¦å…‹é£ŽéŸ³é¢‘
        const stream = await navigator.mediaDevices.getUserMedia({
            audio: {
                sampleRate: TARGET_SAMPLE_RATE,
                channelCount: 1,
                echoCancellation: true,
                noiseSuppression: true,
                autoGainControl: true
            },
            video: false
        });

        // æ£€æŸ¥æ˜¯å¦æœ‰éŸ³é¢‘è½¨é“
        if (stream.getAudioTracks().length === 0) {
            console.error('[WindowsAudioRecorder] No audio track found in stream');
            ipcRenderer.send('update-status', 'âŒ No Microphone Found');
            stream.getTracks().forEach(track => track.stop());
            return;
        }

        mediaStream = stream;
        
        // è®¾ç½® AudioContext
        audioContext = new AudioContext({ sampleRate: TARGET_SAMPLE_RATE });
        const audioTrack = stream.getAudioTracks()[0];
        const audioStream = new MediaStream([audioTrack]);
        
        sourceNode = audioContext.createMediaStreamSource(audioStream);
        
        // åˆ›å»º ScriptProcessor
        // 16kHz sample rate, buffer size 4096 => ~256ms latency
        // buffer size 8192 => ~512ms latency
        // renderer.js uses 8192 for 16kHz, sticking to 4096 for lower latency if possible, or align with renderer
        // Let's use 8192 to match renderer.js stability
        processor = audioContext.createScriptProcessor(8192, 1, 1);
        
        sourceNode.connect(processor);
        processor.connect(audioContext.destination); // å¿…é¡»è¿žæŽ¥åˆ° destination æ‰èƒ½è¿è¡Œ

        processor.onaudioprocess = (e) => {
            if (!isRecording) return;
            
            const inputData = e.inputBuffer.getChannelData(0);
            const pcmData = new Int16Array(inputData.length);
            
            for (let i = 0; i < inputData.length; i++) {
                // Float32 è½¬ Int16
                const s = Math.max(-1, Math.min(1, inputData[i]));
                pcmData[i] = s < 0 ? s * 0x8000 : s * 0x7FFF;
            }
            
            recordedChunks.push(Buffer.from(pcmData.buffer));
        };

        isRecording = true;
        
        // é€šçŸ¥ UI æ›´æ–°çŠ¶æ€
        ipcRenderer.send('update-status', 'ðŸŽ™ï¸ Recording Microphone...');
        console.log('[WindowsAudioRecorder] Microphone Recording Started');

        // ç›‘å¬æµç»“æŸäº‹ä»¶
        stream.getAudioTracks()[0].onended = () => {
            console.log('[WindowsAudioRecorder] Microphone stream ended');
            stopRecording();
        };

    } catch (error) {
        console.error('[WindowsAudioRecorder] Failed to start recording:', error);
        ipcRenderer.send('update-status', 'âŒ Mic Capture Failed: ' + error.message);
        isRecording = false;
    }
}

async function stopRecording() {
    if (!isRecording) return;
    
    console.log('[WindowsAudioRecorder] Stopping Windows Audio Capture...');
    isRecording = false;
    ipcRenderer.send('update-status', 'â³ Processing Audio...');

    // æ¸…ç†èµ„æº
    if (processor) {
        processor.disconnect();
        processor.onaudioprocess = null;
    }
    if (sourceNode) {
        sourceNode.disconnect();
    }
    if (mediaStream) {
        mediaStream.getTracks().forEach(track => track.stop());
    }
    if (audioContext) {
        await audioContext.close();
    }

    // å¤„ç†æ•°æ®
    if (recordedChunks.length === 0) {
        console.warn('[WindowsAudioRecorder] No audio data recorded');
        ipcRenderer.send('update-status', 'âš ï¸ No Audio Recorded');
        return;
    }

    const fullBuffer = Buffer.concat(recordedChunks);
    
    // 1. ä¿å­˜åˆ°æ–‡ä»¶ (å…ˆä¿å­˜)
    const homeDir = os.homedir();
    const audioDir = path.join(homeDir, 'cheddar', 'data', 'audio');
    if (!fs.existsSync(audioDir)) {
        fs.mkdirSync(audioDir, { recursive: true });
    }
    
    const timestamp = Date.now();
    const wavPath = path.join(audioDir, `win_rec_${timestamp}.wav`);
    
    try {
        pcmToWav(fullBuffer, wavPath, TARGET_SAMPLE_RATE, 1, 16);
        console.log('[WindowsAudioRecorder] Saved recording to:', wavPath);
    } catch (e) {
        console.error('[WindowsAudioRecorder] Error saving wav:', e);
    }

    // 2. å‘é€ç»™è½¬å½•æ¨¡åž‹ (æ¨¡æ‹Ÿ renderer.js çš„è¡Œä¸º)
    const base64Audio = fullBuffer.toString('base64');
    
    ipcRenderer.send('update-status', 'Transcribing...');

    // ä½¿ç”¨ save-audio-and-transcribe æ›¿ä»£ send-windows-audio-data
    // è¿™ä¸ª IPC handler åœ¨ index.js ä¸­ï¼Œå®ƒè´Ÿè´£ä¿å­˜æ–‡ä»¶å¹¶è°ƒç”¨ STT (Speech-to-Text)
    ipcRenderer.invoke('save-audio-and-transcribe', {
        pcmBase64: base64Audio,
        sampleRate: TARGET_SAMPLE_RATE // 16000
    }).then(result => {
        if (!result || !result.success) {
            console.error('[WindowsAudioRecorder] Transcription failed:', result?.error);
            ipcRenderer.send('update-status', 'âŒ Transcribe Failed');
        } else {
            // è½¬å½•æˆåŠŸï¼Œindex.js ä¼šå¤„ç†åŽç»­é€»è¾‘ï¼ˆæ¯”å¦‚å‘é€æ–‡æœ¬ç»™ LLMï¼‰
            // æˆ–è€…å®ƒåªæ˜¯è¿”å›žæ–‡æœ¬ï¼Œæˆ‘ä»¬éœ€è¦åœ¨è¿™é‡Œå‘é€ï¼Ÿ
            // è®©æˆ‘ä»¬æ£€æŸ¥ä¸€ä¸‹ renderer.js æ˜¯æ€Žä¹ˆåšçš„ã€‚
            // renderer.js è°ƒç”¨ invoke åŽå¥½åƒæ²¡æœ‰å¤„ç†è¿”å›žå€¼å‘é€ç»™ LLMï¼Ÿ
            // ç­‰ç­‰ï¼Œindex.js çš„ save-audio-and-transcribe å®žçŽ°é‡Œå¹¶æ²¡æœ‰è°ƒç”¨ LLMã€‚
            // å®ƒæ˜¯è°ƒç”¨äº† Whisper è¿˜æ˜¯ä»€ä¹ˆï¼Ÿ
            // è®©æˆ‘ä»¬å†ç¡®è®¤ä¸€ä¸‹ index.js çš„ save-audio-and-transcribeã€‚
        }
    }).catch(err => {
        console.error('[WindowsAudioRecorder] Error invoking save-audio-and-transcribe:', err);
        ipcRenderer.send('update-status', 'âŒ Error');
    });

    recordedChunks = [];
}

module.exports = {
    initialize: () => {
        console.log('[WindowsAudioRecorder] Initializing...');
        ipcRenderer.on('toggle-windows-audio-capture', () => {
            console.log('[WindowsAudioRecorder] Received toggle-windows-audio-capture event');
            toggleRecording();
        });
    }
};
